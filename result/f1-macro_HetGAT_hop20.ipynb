{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using backend: pytorch\n"
     ]
    }
   ],
   "source": [
    "root_dir = '..' # dir of the source code\n",
    "import sys\n",
    "sys.path.append(root_dir)\n",
    "from train import main\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class config:\n",
    "    data = 'ACM'\n",
    "    data_path = '../data/preprocessed/'\n",
    "    model = 'HetGAT'\n",
    "    target_node_type = 'paper'\n",
    "    n_hid = 64\n",
    "    dropout = 0.8\n",
    "    dropout2 = 0.2\n",
    "    learning_rate = 0.005\n",
    "    weight_decay = 0#5e-5\n",
    "    patience = 100\n",
    "    num_iter = 500\n",
    "    num_test = 30\n",
    "    hop = 20\n",
    "    filter_pct = 0.1 # remove the top and bottom filer_pct points before obtaining statistics of test accuracy\n",
    "    log_step = 1000 # training log step\n",
    "    layer_wise = True\n",
    "    average = 'macro' # 'f1 average: can choose either macro or micro.'\n",
    "\n",
    "args = config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "start testing on ACM dataset\n",
      "total time = 67.209, train time/epoch = 0.22907, best_val_f1 (macro) = 0.750, test_f1 (macro) = 0.668\n",
      "total time = 29.860, train time/epoch = 0.22807, best_val_f1 (macro) = 0.569, test_f1 (macro) = 0.611\n",
      "total time = 68.109, train time/epoch = 0.22714, best_val_f1 (macro) = 0.692, test_f1 (macro) = 0.647\n",
      "total time = 78.267, train time/epoch = 0.22709, best_val_f1 (macro) = 0.759, test_f1 (macro) = 0.715\n",
      "total time = 29.780, train time/epoch = 0.22735, best_val_f1 (macro) = 0.597, test_f1 (macro) = 0.521\n",
      "total time = 31.105, train time/epoch = 0.22700, best_val_f1 (macro) = 0.524, test_f1 (macro) = 0.451\n",
      "total time = 79.731, train time/epoch = 0.22664, best_val_f1 (macro) = 0.638, test_f1 (macro) = 0.633\n",
      "total time = 43.579, train time/epoch = 0.22788, best_val_f1 (macro) = 0.542, test_f1 (macro) = 0.579\n",
      "total time = 62.466, train time/epoch = 0.22913, best_val_f1 (macro) = 0.784, test_f1 (macro) = 0.751\n",
      "total time = 31.420, train time/epoch = 0.22940, best_val_f1 (macro) = 0.545, test_f1 (macro) = 0.578\n",
      "total time = 31.168, train time/epoch = 0.22773, best_val_f1 (macro) = 0.546, test_f1 (macro) = 0.538\n",
      "total time = 56.417, train time/epoch = 0.22753, best_val_f1 (macro) = 0.753, test_f1 (macro) = 0.743\n",
      "total time = 53.350, train time/epoch = 0.22714, best_val_f1 (macro) = 0.668, test_f1 (macro) = 0.705\n",
      "total time = 75.872, train time/epoch = 0.22694, best_val_f1 (macro) = 0.759, test_f1 (macro) = 0.728\n",
      "total time = 30.597, train time/epoch = 0.22743, best_val_f1 (macro) = 0.528, test_f1 (macro) = 0.579\n",
      "total time = 78.063, train time/epoch = 0.22726, best_val_f1 (macro) = 0.644, test_f1 (macro) = 0.651\n",
      "total time = 79.907, train time/epoch = 0.23188, best_val_f1 (macro) = 0.816, test_f1 (macro) = 0.737\n",
      "total time = 76.661, train time/epoch = 0.23344, best_val_f1 (macro) = 0.729, test_f1 (macro) = 0.694\n",
      "total time = 31.153, train time/epoch = 0.23491, best_val_f1 (macro) = 0.541, test_f1 (macro) = 0.581\n",
      "total time = 31.340, train time/epoch = 0.23665, best_val_f1 (macro) = 0.551, test_f1 (macro) = 0.604\n",
      "total time = 37.030, train time/epoch = 0.23216, best_val_f1 (macro) = 0.617, test_f1 (macro) = 0.639\n",
      "total time = 30.529, train time/epoch = 0.23733, best_val_f1 (macro) = 0.557, test_f1 (macro) = 0.604\n",
      "total time = 42.021, train time/epoch = 0.22966, best_val_f1 (macro) = 0.777, test_f1 (macro) = 0.734\n",
      "total time = 54.547, train time/epoch = 0.22984, best_val_f1 (macro) = 0.676, test_f1 (macro) = 0.696\n",
      "total time = 91.044, train time/epoch = 0.22821, best_val_f1 (macro) = 0.819, test_f1 (macro) = 0.733\n",
      "total time = 47.071, train time/epoch = 0.22772, best_val_f1 (macro) = 0.640, test_f1 (macro) = 0.632\n",
      "total time = 50.130, train time/epoch = 0.22700, best_val_f1 (macro) = 0.696, test_f1 (macro) = 0.661\n",
      "total time = 42.881, train time/epoch = 0.22699, best_val_f1 (macro) = 0.536, test_f1 (macro) = 0.576\n",
      "total time = 96.096, train time/epoch = 0.22667, best_val_f1 (macro) = 0.641, test_f1 (macro) = 0.651\n",
      "total time = 40.043, train time/epoch = 0.22602, best_val_f1 (macro) = 0.725, test_f1 (macro) = 0.729\n",
      "test macro-f1 (mean, std):  0.6457008010999599 0.07411842514789188\n",
      "test macro-f1 (mean, std) after filter:  0.6512443696255854 0.05392937018994954\n",
      "\n",
      "start testing on IMDB dataset\n",
      "total time = 38.608, train time/epoch = 0.18608, best_val_f1 (macro) = 0.463, test_f1 (macro) = 0.494\n",
      "total time = 35.753, train time/epoch = 0.18797, best_val_f1 (macro) = 0.366, test_f1 (macro) = 0.331\n",
      "total time = 37.926, train time/epoch = 0.18853, best_val_f1 (macro) = 0.370, test_f1 (macro) = 0.370\n",
      "total time = 45.207, train time/epoch = 0.18715, best_val_f1 (macro) = 0.504, test_f1 (macro) = 0.497\n",
      "total time = 43.015, train time/epoch = 0.18749, best_val_f1 (macro) = 0.523, test_f1 (macro) = 0.492\n",
      "total time = 47.487, train time/epoch = 0.18721, best_val_f1 (macro) = 0.522, test_f1 (macro) = 0.500\n",
      "total time = 32.620, train time/epoch = 0.18699, best_val_f1 (macro) = 0.366, test_f1 (macro) = 0.419\n",
      "total time = 34.775, train time/epoch = 0.18753, best_val_f1 (macro) = 0.441, test_f1 (macro) = 0.422\n",
      "total time = 42.196, train time/epoch = 0.18685, best_val_f1 (macro) = 0.478, test_f1 (macro) = 0.474\n",
      "total time = 47.430, train time/epoch = 0.18770, best_val_f1 (macro) = 0.438, test_f1 (macro) = 0.451\n",
      "total time = 47.249, train time/epoch = 0.18907, best_val_f1 (macro) = 0.413, test_f1 (macro) = 0.437\n",
      "total time = 34.166, train time/epoch = 0.18924, best_val_f1 (macro) = 0.410, test_f1 (macro) = 0.399\n",
      "total time = 42.115, train time/epoch = 0.18864, best_val_f1 (macro) = 0.475, test_f1 (macro) = 0.498\n",
      "total time = 38.827, train time/epoch = 0.18829, best_val_f1 (macro) = 0.431, test_f1 (macro) = 0.436\n",
      "total time = 37.490, train time/epoch = 0.18850, best_val_f1 (macro) = 0.406, test_f1 (macro) = 0.400\n",
      "total time = 42.317, train time/epoch = 0.18844, best_val_f1 (macro) = 0.542, test_f1 (macro) = 0.489\n",
      "total time = 45.759, train time/epoch = 0.18746, best_val_f1 (macro) = 0.408, test_f1 (macro) = 0.376\n",
      "total time = 37.770, train time/epoch = 0.18876, best_val_f1 (macro) = 0.341, test_f1 (macro) = 0.386\n",
      "total time = 65.733, train time/epoch = 0.18962, best_val_f1 (macro) = 0.502, test_f1 (macro) = 0.452\n",
      "total time = 68.323, train time/epoch = 0.18909, best_val_f1 (macro) = 0.526, test_f1 (macro) = 0.511\n",
      "total time = 48.127, train time/epoch = 0.18880, best_val_f1 (macro) = 0.369, test_f1 (macro) = 0.380\n",
      "total time = 42.862, train time/epoch = 0.18871, best_val_f1 (macro) = 0.510, test_f1 (macro) = 0.492\n",
      "total time = 63.927, train time/epoch = 0.18842, best_val_f1 (macro) = 0.344, test_f1 (macro) = 0.355\n",
      "total time = 51.768, train time/epoch = 0.18845, best_val_f1 (macro) = 0.488, test_f1 (macro) = 0.462\n",
      "total time = 34.054, train time/epoch = 0.18735, best_val_f1 (macro) = 0.383, test_f1 (macro) = 0.374\n",
      "total time = 33.424, train time/epoch = 0.18895, best_val_f1 (macro) = 0.340, test_f1 (macro) = 0.316\n",
      "total time = 40.341, train time/epoch = 0.18895, best_val_f1 (macro) = 0.476, test_f1 (macro) = 0.485\n",
      "total time = 53.536, train time/epoch = 0.18825, best_val_f1 (macro) = 0.379, test_f1 (macro) = 0.405\n",
      "total time = 35.940, train time/epoch = 0.18862, best_val_f1 (macro) = 0.380, test_f1 (macro) = 0.398\n",
      "total time = 35.717, train time/epoch = 0.18876, best_val_f1 (macro) = 0.528, test_f1 (macro) = 0.508\n",
      "test macro-f1 (mean, std):  0.43360778567131386 0.05619402695042712\n",
      "test macro-f1 (mean, std) after filter:  0.4369620369779543 0.04468771148822848\n",
      "\n",
      "start testing on DBLP dataset\n",
      "total time = 67.150, train time/epoch = 0.38656, best_val_f1 (macro) = 0.399, test_f1 (macro) = 0.425\n",
      "total time = 74.488, train time/epoch = 0.38679, best_val_f1 (macro) = 0.403, test_f1 (macro) = 0.411\n",
      "total time = 81.774, train time/epoch = 0.38667, best_val_f1 (macro) = 0.641, test_f1 (macro) = 0.657\n",
      "total time = 55.372, train time/epoch = 0.38748, best_val_f1 (macro) = 0.361, test_f1 (macro) = 0.384\n",
      "total time = 55.601, train time/epoch = 0.38931, best_val_f1 (macro) = 0.349, test_f1 (macro) = 0.383\n",
      "total time = 101.317, train time/epoch = 0.38828, best_val_f1 (macro) = 0.585, test_f1 (macro) = 0.613\n",
      "total time = 56.912, train time/epoch = 0.38876, best_val_f1 (macro) = 0.354, test_f1 (macro) = 0.358\n",
      "total time = 59.195, train time/epoch = 0.38868, best_val_f1 (macro) = 0.423, test_f1 (macro) = 0.449\n",
      "total time = 62.356, train time/epoch = 0.38830, best_val_f1 (macro) = 0.359, test_f1 (macro) = 0.391\n",
      "total time = 83.701, train time/epoch = 0.38713, best_val_f1 (macro) = 0.344, test_f1 (macro) = 0.314\n",
      "total time = 73.641, train time/epoch = 0.38718, best_val_f1 (macro) = 0.374, test_f1 (macro) = 0.409\n",
      "total time = 79.180, train time/epoch = 0.38750, best_val_f1 (macro) = 0.573, test_f1 (macro) = 0.569\n",
      "total time = 56.926, train time/epoch = 0.38876, best_val_f1 (macro) = 0.498, test_f1 (macro) = 0.442\n",
      "total time = 67.418, train time/epoch = 0.38845, best_val_f1 (macro) = 0.366, test_f1 (macro) = 0.420\n",
      "total time = 51.803, train time/epoch = 0.38810, best_val_f1 (macro) = 0.348, test_f1 (macro) = 0.380\n",
      "total time = 100.776, train time/epoch = 0.38793, best_val_f1 (macro) = 0.350, test_f1 (macro) = 0.312\n",
      "total time = 67.419, train time/epoch = 0.38829, best_val_f1 (macro) = 0.538, test_f1 (macro) = 0.570\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total time = 99.147, train time/epoch = 0.38661, best_val_f1 (macro) = 0.675, test_f1 (macro) = 0.696\n",
      "total time = 55.807, train time/epoch = 0.38722, best_val_f1 (macro) = 0.349, test_f1 (macro) = 0.371\n",
      "total time = 56.708, train time/epoch = 0.38713, best_val_f1 (macro) = 0.479, test_f1 (macro) = 0.530\n",
      "total time = 105.344, train time/epoch = 0.38790, best_val_f1 (macro) = 0.376, test_f1 (macro) = 0.397\n",
      "total time = 177.139, train time/epoch = 0.38746, best_val_f1 (macro) = 0.943, test_f1 (macro) = 0.913\n",
      "total time = 97.967, train time/epoch = 0.38751, best_val_f1 (macro) = 0.496, test_f1 (macro) = 0.516\n",
      "total time = 75.850, train time/epoch = 0.38675, best_val_f1 (macro) = 0.306, test_f1 (macro) = 0.327\n",
      "total time = 65.320, train time/epoch = 0.38663, best_val_f1 (macro) = 0.476, test_f1 (macro) = 0.445\n",
      "total time = 64.471, train time/epoch = 0.38709, best_val_f1 (macro) = 0.248, test_f1 (macro) = 0.255\n",
      "total time = 66.445, train time/epoch = 0.38817, best_val_f1 (macro) = 0.384, test_f1 (macro) = 0.417\n",
      "total time = 89.347, train time/epoch = 0.38800, best_val_f1 (macro) = 0.223, test_f1 (macro) = 0.236\n",
      "total time = 96.156, train time/epoch = 0.38765, best_val_f1 (macro) = 0.383, test_f1 (macro) = 0.423\n",
      "total time = 74.569, train time/epoch = 0.38732, best_val_f1 (macro) = 0.358, test_f1 (macro) = 0.365\n",
      "test macro-f1 (mean, std):  0.44592101670351886 0.13753917393165438\n",
      "test macro-f1 (mean, std) after filter:  0.42954170950984993 0.0757635248947908\n"
     ]
    }
   ],
   "source": [
    "f1s = []\n",
    "datasets = ['ACM', 'IMDB', 'DBLP']\n",
    "for dataset in datasets:\n",
    "    args.data = dataset\n",
    "    if dataset == 'ACM':\n",
    "        args.dropout = 0.8\n",
    "        args.dropout2 = 0.2\n",
    "        weight_decay = 5e-5\n",
    "        args.target_node_type = 'paper'\n",
    "        print('\\nstart testing on ' + dataset + ' dataset')\n",
    "        f1s.append(main(args))\n",
    "    elif dataset == 'IMDB':\n",
    "        args.dropout = 0.8\n",
    "        args.dropout2 = 0.2\n",
    "        weight_decay = 5e-5#0\n",
    "        args.target_node_type = 'movie'\n",
    "        print('\\nstart testing on ' + dataset + ' dataset')\n",
    "        f1s.append(main(args))\n",
    "    elif dataset == 'DBLP':\n",
    "        args.dropout = 0\n",
    "        args.dropout2 = 0\n",
    "        weight_decay = 5e-5\n",
    "        args.target_node_type = 'author'\n",
    "        print('\\nstart testing on ' + dataset + ' dataset')\n",
    "        f1s.append(main(args))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1s = np.array(f1s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5055134537700764, 0.09220549997489921)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from utils import remove_edge_pts\n",
    "# remove some unstable results\n",
    "f1_DBLP = f1s[2][f1s[2] > 0.4]\n",
    "f1 = remove_edge_pts(f1_DBLP, pct=args.filter_pct)\n",
    "f1.mean(), f1.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
